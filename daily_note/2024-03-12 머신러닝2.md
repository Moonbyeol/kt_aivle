
# 데이터 나누기

## 불균형 데이터 정확한 비율로 나눠주기
```python
# 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42, stratify=y)
```
- stratify 로 특정 값을 정확한 비율로 나눠줄 수 있다.




# 표기
y : 실제값
$\bar y$ : 평균값
$\hat{y}$ : 예측값



# 회귀 평가지표
## MSE(Mean Squared Error)

$$\frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가
print('MSE:', mean_squared_error(y_test,y_pred))
```
## RMSE(Root Mean Squared Error)
$$\sqrt \frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가(2가지 방)
print('RMSE:', mean_squared_error(y_test,y_pred)**0.5)
print('RMSE:', mean_squared_error(y_test,y_pred, squared=False))
```
## MAE(Mean Absolute Error)
$$\frac{\displaystyle\sum_{}^{} |y-\hat y|} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_error

# 성능 평가
print('MAE:', mean_absolute_error(y_test,y_pred))
```
## MAPE(Mean Absolute Percentage Error)

$$\frac{\displaystyle\sum_{}^{} \frac{|y-\hat y|}{y}} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_percentage_error

# 성능 평가
print('MAPE:', mean_absolute_percentage_error(y_test,y_pred))
```

## 위 값 모두 작을수록 모델 성능이 좋음



# 오차를 바라보는 다양한 관점

## SST(Sum Squared Total)
$${\displaystyle\sum_{i=1}^{n} (y-\bar y)^2}$$
- 전체 오차
## SSR
$${\displaystyle\sum_{i=1}^{n} (\hat y-\bar y)^2}$$
- 전체 오차 중에서 회귀식이 잡아낸 오차

## SSE
$${\displaystyle\sum_{i=1}^{n} (\hat y- y)^2}$$
- 전체 오차 중에서 회귀식이 여전히 잡아내지 못한 오차

### SST = SSE + SSR


## 결정계수 $R^2$(R-Squared)

$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$
- 회귀모델 평가지표
- MSE로 여전히 설명이 부족한 부분이 있음
- 모델 성능을 잘 해석하기 위해서 만든 MSE의표준화된 버전이 결정 계수임
- 전체 오차 중에서 회귀식이 잡아낸 오차 비율(일반적으로 0~1 사이)
- 오차의 비 또는 설명력이라고도 부름
- $R^2=1$이면 $MSE = 0$ 이고 모델이 데이터를 완벽하게 학습한 것
- $R^2=80\%$ 정확도가 80%가 아니라 평균보다 오차를 80%정도 더 잘 잡아 낸 것이다 라고 읽으면 됨, 평균에 비해 80% 더 실제 값에 가깝다, 설명력이 있다.
```python
# 모듈 불러오기
from sklearn.metrics import r2_score

# 성능 평가
	print('r2:', r2_score(y_test,y_pred))

# 이러한 것도 있다. r2 값과 같다.
model.score(x_test,y_test)
```





# 분류 평가 지표

- 정확도(Accuracy): 1과 0을 정확히 예측
$$\frac {TN+TP}{TN+FP+FN+TP}$$
- 정밀도(Precision): 1이라 예측한 것 중에 정말 1인 비율
$$\frac {TP}{FP+TP}$$
- 재현율(Recall): 실제 1인 것을 1이라고 예측한 비율
$$\frac {TP}{FN+TP}$$
## 혼동 행렬

### Confusion Matrix(오분류표)

- TN(True Negative): 음성으로 잘 예측한 것
- FN(False Negative): 음성으로잘 봇 예측한 것 
- FP(False Positive): 양성으로잘 못 예측한 것
- TP(True Positive): 양성으로 잘 예측한 것


## Accuracy
- 정확도
	- 정분류율 이라고 부르기도 함
$$\frac {TN+TP}{TN+FP+FN+TP}$$
![](https://i.imgur.com/dTNtcqF.png)

## Precision
- 정밀도
	- Positive로 예측한 것(FP + TP)중에서 실제 Positive(TP)인 비율
	- 예) 비가 내릴 것으로 예측한 날 중에서 실제 비가 내린 날의 비율
	- 예) 암이라 예측한 환자 중에서 실제 암인 환자의 비율
- 정밀도가 낮을 경우 발생하는 상황
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
$$\frac {TP}{FP+TP}$$
![](https://i.imgur.com/J1HiXtt.png)

## Recall
- 재현율
	- 실제 Positive(FN + TP) 중에서 Positive로 예측한(TP) 비율
	- 민감도(Sensitivity)라고 부르는 경우가 많음
	- 예) 실제 비가 내린 날 중에서 비가 내릴 것으로 예측한 날의 비율
	- 예) 실제 암인 환자 중에서 암이라고 예측한 환자의 비율
- 재현율이 낮을 경우 발생하는 문제
	- 비가 내리는 날 내리지 않을 것이라 했으니 우산을 챙기지 않아 비를 맞음
	- 암인 사람에게 암이 아니라 했으니 심각한 결과 초래
$$\frac {TP}{FN+TP}$$
![](https://i.imgur.com/hFiu3n0.png)



## Specificity
- 특이도
	- 실제 Negative(TN+FP) 중에서 Negative로 예측한 (TN) 비율
	- 예) 실제 비가 내리지 않는 날 중에서 비가 내리지 않을 것으로 예측한 날의 비율
	- 예) 실제 암이 아닌 환자 중에서 암이 아니라고 예측한 환자의 비율
- 특이도가 낮을 경우 발생하는 문제
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
![](https://i.imgur.com/4f5ZZbY.png)


## F1-Score

- 정밀도와 재현율의 조화 평균
- 분자가 같지만 분모가 다를 경우, 즉 관점이 다른 경우 조화 평균이 큰 의미를 가짐
- 정밀도와 재현율이 적절하게 요구 될 때 사용
![](https://i.imgur.com/bF2XSvs.png)
$$(F1-Score)=2\times\frac{1}{\frac{1}{Precesion}+\frac{1}{Recall}}=\frac{2\times Precesion\times Recall}{Precesion+Recall}$$
- 산술, 기하, 조화 평균 비교



