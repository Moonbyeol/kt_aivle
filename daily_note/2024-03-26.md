![](https://i.imgur.com/fUcQexe.png)
![](https://i.imgur.com/7UKeuck.png)
![](https://i.imgur.com/Tv83GM7.png)
![](https://i.imgur.com/uMynYBz.png)
![](https://i.imgur.com/lm5sP9m.png)

![](https://i.imgur.com/qFBZfzX.png)



# RNN의 문제
- 기억력이 안좋음
- 갈수록 까먹음

# LSTM
- RNN의 단점 보완



```python
timesteps = 14
x2, y2 = temporalize(x, y, timesteps)
x2.shape, y2.shape

x_train, x_val, y_train, y_val = train_test_split(x2, y2, test_size= 53, shuffle = False)

timesteps = x_train[1]
nfeatures = x_train[2]

clear_session()

model = Sequential([
    LSTM(8, input_shape=(timesteps, nfeatures), return_sequences=True),
    LSTM(8),
    Dense(1)        
])

model.summary()

# 모델 학습
model.compile(optimizer=Adam(0.01), loss='mse')
hist = model.fit(x_train,y_train,epochs = 100, verbose=0, validation_split=.2).history

# 그래프
dl_history_plot(hist)

# 예측
pred = model.predict(x_val)
# 평가
mean_absolute_error(y_val,pred)

# 그래프
plt.figure(figsize = (10,6))
plt.plot(y_val, label = 'actual')
plt.plot(pred, label = 'predicted')
plt.legend()
plt.grid()
plt.show()
```



# 학습곡선 함수
```python
# 학습곡선 함수
def dl_history_plot(history):
    plt.figure(figsize=(10,6))
    plt.plot(history['loss'], label='train_err', marker = '.')
    plt.plot(history['val_loss'], label='val_err', marker = '.')

    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend()
    plt.grid()
    plt.show()
```

# 데이터 2 -> 3차원 변환
```python
# 시계열 데이터 전처리 2차원 --> 3차원으로 변환
def temporalize(x, y, timesteps):
    nfeature = x.shape[1]
    output_x = []
    output_y = []
    for i in range(len(x) - timesteps + 1):
        t = []
        for j in range(timesteps):
            t.append(x[[(i + j)], :])
        output_x.append(t)
        output_y.append(y[i + timesteps - 1])
    return np.array(output_x).reshape(-1,timesteps, nfeature), np.array(output_y)
```

