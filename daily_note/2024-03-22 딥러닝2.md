




# 회귀

## Activation

### relu

## Loss Function

### mse



# 분류

## Activation

### sigmoid
- 이진 분시시
## Loss Function

### binary_crossentropy
- 이진 분류시






# 실습 - 분류

```python
n = x_train.shape[1]

clear_session()

model = Sequential([
    Dense(16, input_shape=(n,),activation='relu'),
    Dense(1, activation='sigmoid')
])

model.summary()

model.compile(optimizer=Adam(0.01), loss ='binary_crossentropy')

model.fit(x_train,y_train, epochs=50, validation_split=.2)

# 그래프
dl_history_plot(history)

# 예측 및 검증
pred = model.predict(x_val)
pred = np.where(pred >= 0.5, 1, 0)
print(classification_report(y_val, pred))
```