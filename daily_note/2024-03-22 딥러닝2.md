




# 회귀

## Activation

### relu

## Loss Function

### mse



# 분류

## Activation

### sigmoid
- 이진 분시시
## Loss Function

### binary_crossentropy
- 이진 분류시






# 실습 - 분류

```python
n = x_train.shape[1]

clear_session()

model = Sequential([
    Dense(16, input_shape=(n,),activation='relu'),
    Dense(1, activation='sigmoid')
])

model.summary()

model.compile(optimizer=Adam(0.01), loss ='binary_crossentropy')

model.fit(x_train,y_train, epochs=50, validation_split=.2)

# 그래프
dl_history_plot(history)

# 예측 및 검증
pred = model.predict(x_val)
pred = np.where(pred >= 0.5, 1, 0)
print(classification_report(y_val, pred))
```



# Resampling
- 데이터 불균형 처리
```python
# 불균형 확인
print(data['Attrition'].value_counts(normalize=True))
sns.countplot(x='Attrition', data=data)
plt.grid()
plt.show()


# 불균형 처리
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler()
x_train_ros, y_train_ros = ros.fit_resample(x_train, y_train)

n = x_train_ros.shape[1]

clear_session()

model2 = Sequential([
    Dense(8, input_shape=(n,), activation='relu'),
    Dense(1,activation='sigmoid')
])

model2.summary()

model2.compile(optimizer=Adam(0.01), loss='binary_crossentropy')

hist = model2.fit( x_train_ros, y_train_ros, epochs=50, validation_split=.2).history
```