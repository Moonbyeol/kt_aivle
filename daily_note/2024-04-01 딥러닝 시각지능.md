# CNN

## Convolutional 

## AlexNet

## LeNet








# 이미지 데이터 전처리
```python
resolution = 28

classes = 10

  

x = np.transpose(x, (2, 0, 1))

print(x.shape)

x = x.reshape( (-1, resolution, resolution, 1) )
```

```python
* Data split

    - training set : test set = 8 : 2
    - 재현을 위한 난수 고정 : 2023

from sklearn.model_selection import train_test_split

train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=2024)

train_x.shape, train_y.shape, test_x.shape, test_y.shape


* Scaling

    - min-max scaling

max_n, min_n = train_x.max(), train_x.min()

train_x = (train_x - min_n) / (max_n - min_n)
test_x = (test_x - min_n) / (max_n - min_n)

train_x.max(), train_x.min()


* One-hot encoding

from keras.utils import to_categorical

class_n = len(np.unique(train_y))

train_y = to_categorical(train_y, class_n)
test_y = to_categorical(test_y, class_n)


* Data shape 재확인

train_x.shape, train_y.shape
```

# 모델링
```python
## Sequential API : 레이어를 순차적으로 차곡차곡 쌓는 방식
# 1. 세션 클리어
# keras.backend.clear_session()
keras.utils.clear_session()

# 2. 모델 발판 선언 : 순차적으로 쌓을 발판
model = keras.models.Sequential( )

# 3. 레이어 블록 조립 : .add( )
model.add( keras.layers.Input(shape=(28,28,1)) )
model.add( keras.layers.Flatten())
model.add( keras.layers.Dense(256, activation='relu'))
model.add( keras.layers.BatchNormalization())
model.add( keras.layers.Dropout(0.2) )
model.add( keras.layers.Dense(10, activation='softmax'))


# 4. 컴파일
model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy,
              metrics=['accuracy']
              )

# 요약
model.summary()

* Early stopping

from keras.callbacks import EarlyStopping

es = EarlyStopping(monitor='val_loss',        # 얼리스토핑의 관측 지표
                   min_delta=0,               # Threshold. 지표의 성능 개선 임계값.
                   patience=5,                # 성능 개선이 발생하지 않을 때, 몇 epochs 더 진행할 것인가.
                   verbose=1,                 # 얼리스토핑 발생한 epoch 알려줌
                   restore_best_weights=True, # 최적의 가중치를 가진 epoch 시점으로 가중치를 되돌림.
                   )

* .fit( )

model.fit(train_x, train_y, validation_split=0.2,
          epochs=10000, verbose=1,
          callbacks=[es]
          )

* .evaluate( )

model.evaluate(test_x, test_y)

* .predict( )

y_pred = model.predict(test_x)

# 원핫 인코딩 한 것을 다시 묶어주는 코드
# 평가 지표 및 실제 데이터 확인을 위해 필요

y_pred_arg = np.argmax(y_pred, axis=1)
test_y_arg = np.argmax(test_y, axis=1)

y_pred_arg.shape
y_pred_arg[:5]

* 평가 지표

from sklearn.metrics import classification_report

class_names = ['A', 'B', 'C', 'D', 'E', 'F',' G', 'H', 'I', 'J']

print( classification_report(test_y_arg, y_pred_arg, target_names=class_names) )
```

# Visualization
```python
* 실제 데이터 확인

letters_str = "ABCDEFGHIJ"

rand_idx = np.random.randint(0, len(y_pred_arg))
test_idx = test_y_arg[rand_idx]
pred_idx = y_pred_arg[rand_idx]
class_prob = np.floor( y_pred[rand_idx]*100 )

print(f'idx = {rand_idx}')
print(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')
print(f'모델의 예측 : {letters_str[pred_idx]}')
print(f'모델의 클래스별 확률 : ')
print('-------------------')
for idx, val in enumerate(letters_str) :
    print(val, class_prob[idx])
print('=================================================')

if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :
    print('정답')
else :
    print('땡')

plt.imshow(test_x[rand_idx], cmap='gray')
plt.show()


* 틀린 이미지만 확인해보기

temp = (test_y_arg == y_pred_arg)
false_idx = np.where(temp==False)[0]
false_len = len(false_idx)
false_len

letters_str = "ABCDEFGHIJ"

rand_idx = false_idx[np.random.randint(0, false_len)]
test_idx = test_y_arg[rand_idx]
pred_idx = y_pred_arg[rand_idx]
class_prob = np.floor( y_pred[rand_idx]*100 )

print(f'idx = {rand_idx}')
print(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')
print(f'모델의 예측 : {letters_str[pred_idx]}')
print(f'모델의 클래스별 확률 : ')
print('-------------------')
for idx, val in enumerate(letters_str) :
    print(val, class_prob[idx])
print('=================================================')

if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :
    print('정답')
else :
    print('땡')

plt.imshow(test_x[rand_idx], cmap='gray')
plt.show()
```