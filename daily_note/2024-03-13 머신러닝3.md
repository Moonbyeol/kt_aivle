
# LinearRegressor
# 단순 회귀의회귀 계수

```python
model.coef_ # 회귀계수(=가중치)
model.intercept_ # 편향
```

# 다중 회귀
- 여러독립변수가 종속변수에 영향을 미치는 선형 회귀
- y값을 설명하기 위해서는 여러 개의 x 값이 필요한 경우
	- 예: 여러 요인들에 의해 보스턴 지역 집 값이 결정 됨
- 회귀식:

```python
print(list(x_train))
print(model.coef_)
print(model.intercept)
```
위 출력이 아래와 같다면
```
['Temp','Wind','Solar.R']
[1.523234  -3.56981701  0.06755929]
-53.3734766
```
$$Ozone = -53.37 + 1.52 temp - 3.57 Wind + 0.07 solar.R$$

# 회귀

```python
# 회귀계수 확인
print('가중치(기울기):',model.coef_)
print('편향(절편):',model.intercept_)
```

```python
# 회귀선 표시
dist_mean = y_train.mean()
plt.scatter(x_test,y_test)
plt.scatter(x_train,y_train)
plt.plot(speed, dist, color='r')
plt.axhline(dist_mean, color='r', linestyle='--')
plt.title('Speed & Distance', size=20, pad=10)
plt.ylabel('Dist(ft)')
plt.xlabel('Speed(mph)')
plt.show()
```

```python
# 시각화
plt.plot(y_test.values, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.ylabel('Dist(ft)')
plt.show()
```


# KNN

# 정규화
```python
# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

# 정규화
scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
```



# Decision Tree

## 불순도
### 지니 불순도
- 지니의 불순도가 낮을수록 순도가 높음
- 0.5의 경우 정확히 반반
- 0.5보다 작아질수록 순도가 높다고 봄


## 엔트로피(Entropy)


## 정보 이득(Information Gain)
- Information Gain
- 엔트로피는 단지 속성의 불순도를 표현
- 우리가 알고 싶은 것 = 어떤 속성이 얼마나 많은 정보를 제공하는가!


## 주요 하이퍼파라미터
### max_depth
- 트리의 최대 깊이(기본 값: None)

### min_samples_split
- 노드를 분할하기 위한 최소한의 샘플 개수(기본 값: 2)

### min_samples_leaf
- 리프 노드가 되기 위한 최소한의 샘플 수(기본 값: 1)

### max_feature
- 최선의 분할을 위해 고려할 Feautre수(기본 값: None)



## 트리 시각화
```python
# 시각화 모듈 불러오기
from sklearn.tree import export_graphviz
from IPython.display import Image

# 이미지 파일 만들기
export_graphviz(model,                                 # 모델 이름
                out_file='tree.dot',                   # 파일 이름
                feature_names=x.columns,               # Feature 이름
                class_names=['die', 'survived'],       # Target Class 이름
                rounded=True,                          # 둥근 테두리
                precision=2,                           # 불순도 소숫점 자리수
                max_depth=5,                           # 표시할 트리 깊이
                filled=True)                           # 박스 내부 채우기

# 파일 변환
!dot tree.dot -Tpng -otree.png -Gdpi=300

# 이미지 파일 표시
Image(filename='tree.png')
```

## 변수 중요도 시각화
```python
# 데이터프레임 만들기
df = pd.DataFrame()
df['feature']= list(x)
df['importance']= model.feature_importances_

df.sort_values(by='importance', ascending=True, inplace=True)

# 시각화
plt.figure(figsize=(5, 5))
plt.barh(df['feature'], df['importance'])
plt.show()
```

