
# 과대적합, 과소적합
- 과대적합
	- 학습 데이터에 대해서는 성능이 매우 좋은데, 평가 데이터에 대해서는 성능이 매우 좋지 않은 경우
	- 학습 데이터에 대해서만 잘 맞는 모델 -> 실전에서 예측 성능이 좋지 않음
- 과소적합
	- 학습 데이터보다 평가 데이터에 대한 성능이 매우 좋거나, 모든 데이터에 대한 성능이 매우 안 좋은 경우
	- 모델이 너무 단순하여 학습 데이터에 대해 적절히 훈련되지 않은 경우

# Logistic Regressor
- 이름은 회귀이지만 분류 모델임

## 시그모이드 함수(로지스틱 함수)
- 시그모이드 함수
- 확률 값 p는선형 판별식 값이 커지면 1, 작아지면 0에 가까운 값이 됨
- (-무한대,무한대)범위를 갖는 선형 판별식 결과로 (0,1)('()'는 해당 숫자를 포함하지 않는 다는 것을뜻함. 포함은 '\[]' )범위의 확률 값을 얻게 됨
- 기본적으로 확률 값 0.5를 임계값으로 하여 이보다 크면 1, 아니면 0으로 분류함
- x 데이터가 주어졌을 때 확률을 예측하는로지스틱 회귀분석은 학습 데이터를 잘 설명하는 선형 판별식의 기울기(a)와 절편(b)을 찾는 문제

```python
# 1단계: 불러오기
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
```

```python
# 확률값 확인
model.predict_proba(x_test)
```

```python
# 예측값 확인
print(y_test.values[:10])
print(y_pred[:10])

# 확률값 확인
p = model.predict_proba(x_test)

# 
p1 = p[:,[1]]
p1[:10]

# 임계값 조정
y_pred2 = np.array(['STAY' if x > 0.4 else 'LEAVE' for x in p1])
print(y_pred2[:20])
print(classification_report(y_test,y_pred2))
```


# Random split
- 일반화 성능, 즉 이후 새로운 데이터에 대한 모델의 성능을 예측하지 못한 상태에서 최종 평가를 수행
- 검증용 데이터가 모델의 일반화된 성능을 예측할 수 있게 도와 줌
- 하지만 이것 역시 단 하나의 데이터 셋에 대한 추정일 뿐
- 단 하나의 데이터셋에서 얻은 성능으로 정확도에 확신을 가질 수 없음
- 결국 더욱 정교한 평가 절차가 필요


# K-분할 교차 검증
- K-Fold Cross Validation
- 모든 데이터가 평가에 한 번, 학습에 k-1번 사용
- k개의 분할(Fold)에 대한 성능을 예측->평균과 표준편차 계산 -> 일반화 성능
- 단, k는 2 이상이 되어야 함(최소한 한 개씩의 학습용, 검증용 데이터가 필요)

## 장점
- 모든 데이터를 학습과 평가에 사용할 수 있음
- 좀 더 일반화된 모델을 만들 수 있음

## 단점
- 반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요된다





# 모델 비교 성능 예측
# knn
```python
# 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = KNeighborsClassifier()

# 검증하기
cv_score = cross_val_score(model, x_train_s,y_train, cv=10, scoring='accuracy')

# 확인
print(cv_score)
print(cv_score.mean())
result={}
result['KNN']= cv_score.mean()
```

## Dctree
```python
# 불러오기
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = DecisionTreeClassifier(random_state=1, max_depth=5)

# 검증하기
cv_score = cross_val_score(model, x_train_s,y_train, cv=10, scoring='accuracy')

# 확인
print(cv_score)
print(cv_score.mean())
result['Decision tree']= cv_score.mean()
```

## LO REGRES
```python
# 불러오기
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# 선언하기
model = LogisticRegression()

# 검증하기
cv_score = cross_val_score(model, x_train_s,y_train, cv=10, scoring='accuracy')

# 확인
print(cv_score)
print(cv_score.mean())
result['Logistic Regression']= cv_score.mean()
```



# Hyperparameter
- 알고리즘을 사용해 모델링할 때 모델 성능을 최적화하기 위해 조절할 수 있는 매개변수
	- knn 알고리즘의 n_neighbors, Decision Tree 알고리즘의 max_depth 등
- 튜닝 하는 방법에 정답은 없음
	- 다양한 시도


## KNN
 k 값에 따라 성능이 달라짐
 보통데이터 건수의 제곱근으로 결정하는 경우 종종 있음
 k 값이 가장 클 때가장 단순 모델
 k 값이 작을 수록 복잡한 모델이 됨



## Decision Tree
- max_depth
- min_samples_leaf
	- leaf가 되기 위한 최소한의 샘플 데이터 수
	- 클수록단순해 짐 
- min_samples-split
	- 노드를분할하기 위한 최소한의 샘플 데이터 수
	- 이 값이 클 수록 모델이 단순해 짐





# 파라미터 값에 대한 고민
- knn 알고리즘의 경우 이웃 개수인 k 값, 즉n_neighbors 옵션 값을 어떻게 설정하는 가에 따라 모델 성능이 달라짐
- 생각해 볼 수 있는 방법
	- 그리드 서치
	- 랜덤 서치


