
# 과대적합, 과소적합
- 과대적합
	- 학습 데이터에 대해서는 성능이 매우 좋은데, 평가 데이터에 대해서는 성능이 매우 좋지 않은 경우
	- 학습 데이터에 대해서만 잘 맞는 모델 -> 실전에서 예측 성능이 좋지 않음
- 과소적합
	- 학습 데이터보다 평가 데이터에 대한 성능이 매우 좋거나, 모든 데이터에 대한 성능이 매우 안 좋은 경우
	- 모델이 너무 단순하여 학습 데이터에 대해 적절히 훈련되지 않은 경우

# Logistic Regressor
- 이름은 회귀이지만 분류 모델임

## 시그모이드 함수(로지스틱 함수)
- 시그모이드 함수
- 확률 값 p는선형 판별식 값이 커지면 1, 작아지면 0에 가까운 값이 됨
- (-무한대,무한대)범위를 갖는 선형 판별식 결과로 (0,1)('()'는 해당 숫자를 포함하지 않는 다는 것을뜻함. 포함은 '\[]' )범위의 확률 값을 얻게 됨
- 기본적으로 확률 값 0.5를 임계값으로 하여 이보다 크면 1, 아니면 0으로 분류함
- x 데이터가 주어졌을 때 확률을 예측하는로지스틱 회귀분석은 학습 데이터를 잘 설명하는 선형 판별식의 기울기(a)와 절편(b)을 찾는 문제

```python
# 1단계: 불러오기
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
```

```python
# 확률값 확인
model.predict_proba(x_test)
```

```python
# 예측값 확인
print(y_test.values[:10])
print(y_pred[:10])

# 확률값 확인
p = model.predict_proba(x_test)

# 
p1 = p[:,[1]]
p1[:10]

# 임계값 조정
y_pred2 = np.array(['STAY' if x > 0.4 else 'LEAVE' for x in p1])
print(y_pred2[:20])
print(classification_report(y_test,y_pred2))
```


# Random split
- 일반화 성능, 즉 이후 새로운 데이터에 대한 모델의 성능을 예측하지 못한 상태에서 최종 평가를 수행
- 검증용 데이터가 모델의 일반화된 성능을 예측할 수 있게 도와 줌
- 하지만 이것 역시 단 하나의 데이터 셋에 대한 추정일 뿐
- 단 하나의 데이터셋에서 얻은 성능으로 정확도에 확신을 가질 수 없음
- 결국 더욱 정교한 평가 절차가 필요


# K-분할 교차 검증
- K-Fold Cross Validation
- 모든 데이터가 평가에 한 번, 학습에 k-1번 사용
- k개의 분할(Fold)에 대한 성능을 예측->평균과 표준편차 계산 -> 일반화 성능
- 단, k는 2 이상이 되어야 함(최소한 한 개씩의 학습용, 검증용 데이터가 필요)

