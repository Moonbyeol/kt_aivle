# 경고 무시
```python
warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'
```
# 데이터 나누기
```python
from sklearn.model_selection import train_test_split

# target 확인
target = 'ADMIT'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[: , target]

# 7:3으로 분리
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=42)
# stratify=y 정확한 비율로 나눠주는 옵션
```

# 분류
## 모델링
```python
# 1단계: 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 2단계: 선언하기
model = KNeighborsClassifier()
model

# 3단계: 학습하기
model.fit(x_train, y_train)

# 4단계: 예측하기
y_pred = model.predict(x_test)
y_pred

# 5단계: 평가하기
print('accuracy:', accuracy_score(y_test, y_pred)
```

## 평가 지표
### Accuracy
- 정확도(정분류율)
	- 1과 0을 정확히 예측
$$\frac {TN+TP}{TN+FP+FN+TP}$$
![](https://i.imgur.com/dTNtcqF.png)
```python
# 모듈 불러오기
from sklearn.metrics import accuracy_score

# 성능 평가
print('정확도:',accuracy_score(y_test,y_pred))

# 평가 성능
model.score(x_test,y_test)
# 학습 성능
model.score(x_train,y_train)
```

### Precision
- 정밀도
	- Positive로 예측한 것(FP + TP)중에서 실제 Positive(TP)인 비율
	- 예) 비가 내릴 것으로 예측한 날 중에서 실제 비가 내린 날의 비율
	- 예) 암이라 예측한 환자 중에서 실제 암인 환자의 비율
- 정밀도가 낮을 경우 발생하는 상황
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
$$\frac {TP}{FP+TP}$$
![](https://i.imgur.com/J1HiXtt.png)

```python
# 모듈 불러오기
from sklearn.metrics import precision_score

# 성능 평가
print('정밀도:',precision_score(y_test,y_pred))
print('정밀도:',precision_score(y_test,y_pred, average='binary'))
print('정밀도:',precision_score(y_test,y_pred, average=None))
print('정밀도:',precision_score(y_test,y_pred, average='macro'))
print('정밀도:',precision_score(y_test,y_pred, average='weighted'))
```
### Recall
- 재현율
	- 실제 Positive(FN + TP) 중에서 Positive로 예측한(TP) 비율
	- 민감도(Sensitivity)라고 부르는 경우가 많음
	- 예) 실제 비가 내린 날 중에서 비가 내릴 것으로 예측한 날의 비율
	- 예) 실제 암인 환자 중에서 암이라고 예측한 환자의 비율
- 재현율이 낮을 경우 발생하는 문제
	- 비가 내리는 날 내리지 않을 것이라 했으니 우산을 챙기지 않아 비를 맞음
	- 암인 사람에게 암이 아니라 했으니 심각한 결과 초래
$$\frac {TP}{FN+TP}$$
![](https://i.imgur.com/hFiu3n0.png)

```python
# 모듈 불러오기
from sklearn.metrics import recall_score

# 성능 평가
print('재현율:',recall_score(y_test,y_pred, average=None))
```

### Specificity
- 특이도
	- 실제 Negative(TN+FP) 중에서 Negative로 예측한 (TN) 비율
	- 예) 실제 비가 내리지 않는 날 중에서 비가 내리지 않을 것으로 예측한 날의 비율
	- 예) 실제 암이 아닌 환자 중에서 암이 아니라고 예측한 환자의 비율
- 특이도가 낮을 경우 발생하는 문제
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
![](https://i.imgur.com/4f5ZZbY.png)

### F1-Score
- 정밀도와 재현율의 조화 평균
- 분자가 같지만 분모가 다를 경우, 즉 관점이 다른 경우 조화 평균이 큰 의미를 가짐
- 정밀도와 재현율이 적절하게 요구 될 때 사용
![](https://i.imgur.com/bF2XSvs.png)
$$(F1-Score)=2\times\frac{1}{\frac{1}{Precesion}+\frac{1}{Recall}}=\frac{2\times Precesion\times Recall}{Precesion+Recall}$$
- 산술, 기하, 조화 평균 비교
```python
# 모듈 불러오기
from sklearn.metrics import f1_score

# 성능 평가
print('F1:',f1_score(y_test,y_pred, average=None))
```

### classification Report
```python
# 모듈 불러오기
from sklearn.metrics import classification_report

# 성능 평가
print(classification_report(y_test,y_pred))
```


# 회귀
## 모델링
```python
# 1단계: 불러오기
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# 2단계: 선언하기
model = LinearRegression()
model

# 3단계: 학습하기
model.fit(x_train,y_train)

# 4단계: 예측하기
y_pred = model.predict(x_test)
y_pred

# 5단계: 평가하기
print('MAE:', mean_absolute_error(y_test, y_pred))

# 시각화
plt.plot(y_test.values, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.show()
```

## 평가 지표
### MSE(Mean Squared Error)

$$\frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가
print('MSE:', mean_squared_error(y_test,y_pred))
```
### RMSE(Root Mean Squared Error)
$$\sqrt \frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가(2가지 방)
print('RMSE:', mean_squared_error(y_test,y_pred)**0.5)
print('RMSE:', mean_squared_error(y_test,y_pred, squared=False))
```
### MAE(Mean Absolute Error)
$$\frac{\displaystyle\sum_{}^{} |y-\hat y|} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_error

# 성능 평가
print('MAE:', mean_absolute_error(y_test,y_pred))
```
### MAPE(Mean Absolute Percentage Error)

$$\frac{\displaystyle\sum_{}^{} \frac{|y-\hat y|}{y}} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_percentage_error

# 성능 평가
print('MAPE:', mean_absolute_percentage_error(y_test,y_pred))
```

### 위 값 모두 작을수록 모델 성능이 좋음


### 결정계수 $R^2$(R-Squared)

$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$
- MSE로 여전히 설명이 부족한 부분이 있음
- 모델 성능을 잘 해석하기 위해서 만든 MSE의표준화된 버전이 결정 계수임
- 전체 오차 중에서 회귀식이 잡아낸 오차 비율(일반적으로 0~1 사이)
- 오차의 비 또는 설명력이라고도 부름
- $R^2=1$이면 $MSE = 0$ 이고 모델이 데이터를 완벽하게 학습한 것
- $R^2=80\%$ 정확도가 80%가 아니라 평균보다 오차를 80%정도 더 잘 잡아 낸 것이다 라고 읽으면 됨, 평균에 비해 80% 더 실제 값에 가깝다, 설명력이 있다.
```python
# 모듈 불러오기
from sklearn.metrics import r2_score

# 성능 평가
	print('r2:', r2_score(y_test,y_pred))

# 이러한 것도 있다. r2 값과 같다.
model.score(x_test,y_test)
```
#### SST(Sum Squared Total)
$${\displaystyle\sum_{i=1}^{n} (y-\bar y)^2}$$
- 전체 오차
#### SSR
$${\displaystyle\sum_{i=1}^{n} (\hat y-\bar y)^2}$$
- 전체 오차 중에서 회귀식이 잡아낸 오차
#### SSE
$${\displaystyle\sum_{i=1}^{n} (\hat y- y)^2}$$
- 전체 오차 중에서 회귀식이 여전히 잡아내지 못한 오차
#### SST = SSE + SSR