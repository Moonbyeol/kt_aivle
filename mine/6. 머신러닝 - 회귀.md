# 회귀
![](https://i.imgur.com/wOtAt2e.png)
# 모델링
```python
# 1단계: 불러오기
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# 2단계: 선언하기
model = LinearRegression()
model

# 3단계: 학습하기
model.fit(x_train,y_train)

# 4단계: 예측하기
y_pred = model.predict(x_test)
y_pred

# 5단계: 평가하기
print('MAE:', mean_absolute_error(y_test, y_pred))

# 시각화
plt.plot(y_test.values, label='Actual')
plt.plot(y_pred, label='Predicted')
plt.legend()
plt.show()
```

# 평가 지표
### MSE(Mean Squared Error)

$$\frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가
print('MSE:', mean_squared_error(y_test,y_pred))
```
### RMSE(Root Mean Squared Error)
$$\sqrt \frac{\displaystyle\sum_{}^{} (y-\hat y)^2} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_squared_error

# 성능 평가(2가지 방)
print('RMSE:', mean_squared_error(y_test,y_pred)**0.5)
print('RMSE:', mean_squared_error(y_test,y_pred, squared=False))
```
### MAE(Mean Absolute Error)
$$\frac{\displaystyle\sum_{}^{} |y-\hat y|} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_error

# 성능 평가
print('MAE:', mean_absolute_error(y_test,y_pred))
```
### MAPE(Mean Absolute Percentage Error)

$$\frac{\displaystyle\sum_{}^{} \frac{|y-\hat y|}{y}} {n}$$
```python
# 모듈 불러오기
from sklearn.metrics import mean_absolute_percentage_error

# 성능 평가
print('MAPE:', mean_absolute_percentage_error(y_test,y_pred))
```

### 위 값 모두 작을수록 모델 성능이 좋음


### 결정계수 $R^2$(R-Squared)

$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$
- MSE로 여전히 설명이 부족한 부분이 있음
- 모델 성능을 잘 해석하기 위해서 만든 MSE의표준화된 버전이 결정 계수임
- 전체 오차 중에서 회귀식이 잡아낸 오차 비율(일반적으로 0~1 사이)
- 오차의 비 또는 설명력이라고도 부름
- $R^2=1$이면 $MSE = 0$ 이고 모델이 데이터를 완벽하게 학습한 것
- $R^2=80\%$ 정확도가 80%가 아니라 평균보다 오차를 80%정도 더 잘 잡아 낸 것이다 라고 읽으면 됨, 평균에 비해 80% 더 실제 값에 가깝다, 설명력이 있다.
```python
# 모듈 불러오기
from sklearn.metrics import r2_score

# 성능 평가
	print('r2:', r2_score(y_test,y_pred))

# 이러한 것도 있다. r2 값과 같다.
model.score(x_test,y_test)
```
#### SST(Sum Squared Total)
$${\displaystyle\sum_{i=1}^{n} (y-\bar y)^2}$$
- 전체 오차
#### SSR
$${\displaystyle\sum_{i=1}^{n} (\hat y-\bar y)^2}$$
- 전체 오차 중에서 회귀식이 잡아낸 오차
#### SSE
$${\displaystyle\sum_{i=1}^{n} (\hat y- y)^2}$$
- 전체 오차 중에서 회귀식이 여전히 잡아내지 못한 오차
#### SST = SSE + SSR