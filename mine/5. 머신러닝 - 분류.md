
# 데이터 나누기

```python
from sklearn.model_selection import train_test_split

# target 확인
target = 'ADMIT'

# 데이터 분리
x = data.drop(target, axis=1)
y = data.loc[: , target]

# 7:3으로 분리
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=42)
# stratify=y 정확한 비율로 나눠주는 옵션
```
## 경고 무시
```python
warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format = 'retina'
```

## 한글
```python
# 시각화 한글폰트 설정을 위해 아래 코드를 실행하세요.
plt.rc('font', family='Malgun Gothic')
sns.set(font="Malgun Gothic",#"NanumGothicCoding",
        rc={"axes.unicode_minus":False}, # 마이너스 부호 깨짐 현상 해결
        style='darkgrid')
```
# 분류
![](https://i.imgur.com/wOtAt2e.png)
# 모델링
```python
# 1단계: 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 2단계: 선언하기
model = KNeighborsClassifier()
model

# 3단계: 학습하기
model.fit(x_train, y_train)

# 4단계: 예측하기
y_pred = model.predict(x_test)
y_pred

# 5단계: 평가하기
print('accuracy:', accuracy_score(y_test, y_pred)
```

## k-fold cross-validation

```python
# 1단계: 불러오기
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import cross_val_score

# 2단계: 선언하기
model = DecisionTreeClassifier(max_depth=3)

# 3단계: 검증하기
cv_score= cross_val_score(model, x_train, y_train, cv=10)

# 확인
print(cv_score)
print(cv_score.mean())
```



# 평가 지표
## Accuracy
- 정확도(정분류율)
	- 1과 0을 정확히 예측
$$\frac {TN+TP}{TN+FP+FN+TP}$$
![](https://i.imgur.com/dTNtcqF.png)
```python
# 모듈 불러오기
from sklearn.metrics import accuracy_score

# 성능 평가
print('정확도:',accuracy_score(y_test,y_pred))

# 평가 성능
model.score(x_test,y_test)
# 학습 성능
model.score(x_train,y_train)
```

## Precision
- 정밀도
	- Positive로 예측한 것(FP + TP)중에서 실제 Positive(TP)인 비율
	- 예) 비가 내릴 것으로 예측한 날 중에서 실제 비가 내린 날의 비율
	- 예) 암이라 예측한 환자 중에서 실제 암인 환자의 비율
- 정밀도가 낮을 경우 발생하는 상황
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
$$\frac {TP}{FP+TP}$$
![](https://i.imgur.com/J1HiXtt.png)

```python
# 모듈 불러오기
from sklearn.metrics import precision_score

# 성능 평가
print('정밀도:',precision_score(y_test,y_pred))
print('정밀도:',precision_score(y_test,y_pred, average='binary'))
print('정밀도:',precision_score(y_test,y_pred, average=None))
print('정밀도:',precision_score(y_test,y_pred, average='macro'))
print('정밀도:',precision_score(y_test,y_pred, average='weighted'))
```
## Recall
- 재현율
	- 실제 Positive(FN + TP) 중에서 Positive로 예측한(TP) 비율
	- 민감도(Sensitivity)라고 부르는 경우가 많음
	- 예) 실제 비가 내린 날 중에서 비가 내릴 것으로 예측한 날의 비율
	- 예) 실제 암인 환자 중에서 암이라고 예측한 환자의 비율
- 재현율이 낮을 경우 발생하는 문제
	- 비가 내리는 날 내리지 않을 것이라 했으니 우산을 챙기지 않아 비를 맞음
	- 암인 사람에게 암이 아니라 했으니 심각한 결과 초래
$$\frac {TP}{FN+TP}$$
![](https://i.imgur.com/hFiu3n0.png)

```python
# 모듈 불러오기
from sklearn.metrics import recall_score

# 성능 평가
print('재현율:',recall_score(y_test,y_pred, average=None))
```

## Specificity
- 특이도
	- 실제 Negative(TN+FP) 중에서 Negative로 예측한 (TN) 비율
	- 예) 실제 비가 내리지 않는 날 중에서 비가 내리지 않을 것으로 예측한 날의 비율
	- 예) 실제 암이 아닌 환자 중에서 암이 아니라고 예측한 환자의 비율
- 특이도가 낮을 경우 발생하는 문제
	- 비가 오지 않는데 비가 온다고 했으니 불필요한 우산을 챙기는 수고 발생
	- 암이 아닌데 암이라 했으니 불필요한 치료 발생
![](https://i.imgur.com/4f5ZZbY.png)

## F1-Score
- 정밀도와 재현율의 조화 평균
- 분자가 같지만 분모가 다를 경우, 즉 관점이 다른 경우 조화 평균이 큰 의미를 가짐
- 정밀도와 재현율이 적절하게 요구 될 때 사용
![](https://i.imgur.com/bF2XSvs.png)
$$(F1-Score)=2\times\frac{1}{\frac{1}{Precesion}+\frac{1}{Recall}}=\frac{2\times Precesion\times Recall}{Precesion+Recall}$$
- 산술, 기하, 조화 평균 비교
```python
# 모듈 불러오기
from sklearn.metrics import f1_score

# 성능 평가
print('F1:',f1_score(y_test,y_pred, average=None))
```

## classification Report
```python
# 모듈 불러오기
from sklearn.metrics import classification_report

# 성능 평가
print(classification_report(y_test,y_pred))
```


